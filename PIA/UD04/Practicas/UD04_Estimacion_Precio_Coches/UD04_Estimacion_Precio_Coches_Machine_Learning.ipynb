{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimación del Precio de Venta en Vehículos de Ocasión 🚗\n",
    "\n",
    "En este notebook se desarrolla un modelo de red neuronal para predecir el precio de venta de vehículos usados a partir de 7 variables independientes. Se incluyen pasos de:\n",
    "- **Carga y exploración del dataset**\n",
    "- **Limpieza y preprocesamiento de datos**\n",
    "- **Ingeniería de características**\n",
    "- **División en conjuntos de entrenamiento y prueba**\n",
    "- **Construcción, entrenamiento y evaluación de la red neuronal**\n",
    "\n",
    "El dataset se asume en un archivo `true_car_listings.csv` con las siguientes columnas:\n",
    "- **Price**: Variable objetivo.\n",
    "- **Year**: Año en que se compró el vehículo.\n",
    "- **Mileage**: Número de kilómetros recorridos.\n",
    "- **City**: Ciudad en la que se vendió.\n",
    "- **State**: Estado en el que se vendió.\n",
    "- **Vin**: Identificador único del vehículo.\n",
    "- **Make**: Fabricante.\n",
    "- **Model**: Modelo del vehículo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 📚 Importacion de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "# Configuración de Matplotlib para gráficos en línea\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "# Configuración de Matplotlib para gráficos en línea\n",
    "%matplotlib inline\n",
    "\n",
    "#Importamos modelos predictivos regresion\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga y Exploración del Dataset\n",
    "\n",
    "En este paso se carga el archivo CSV y se exploran las primeras filas y la estructura del dataset para entender mejor los datos con los que trabajaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas del dataset:\n",
      "   Price  Year  Mileage              City State                Vin   Make  \\\n",
      "0   8995  2014    35725           El Paso    TX  19VDE2E53EE000083  Acura   \n",
      "1  10888  2013    19606  Long Island City    NY  19VDE1F52DE012636  Acura   \n",
      "2   8995  2013    48851           El Paso    TX  19VDE2E52DE000025  Acura   \n",
      "3  10999  2014    39922           Windsor    CO  19VDE1F71EE003817  Acura   \n",
      "4  14799  2016    22142            Lindon    UT  19UDE2F32GA001284  Acura   \n",
      "\n",
      "          Model  \n",
      "0    ILX6-Speed  \n",
      "1    ILX5-Speed  \n",
      "2    ILX6-Speed  \n",
      "3    ILX5-Speed  \n",
      "4  ILXAutomatic  \n",
      "\n",
      "Información del dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 852122 entries, 0 to 852121\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   Price    852122 non-null  int64 \n",
      " 1   Year     852122 non-null  int64 \n",
      " 2   Mileage  852122 non-null  int64 \n",
      " 3   City     852122 non-null  object\n",
      " 4   State    852122 non-null  object\n",
      " 5   Vin      852122 non-null  object\n",
      " 6   Make     852122 non-null  object\n",
      " 7   Model    852122 non-null  object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 52.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el dataset\n",
    "df = pd.read_csv('true_car_listings.csv')\n",
    "print(\"Primeras filas del dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Información general del dataset\n",
    "print(\"\\nInformación del dataset:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Limpieza y Preprocesamiento de los Datos\n",
    "\n",
    "### 2.1 Eliminación de Columnas Innecesarias\n",
    "Eliminamos la columna `Vin` ya que es un identificador único que no aporta información para la predicción.\n",
    "\n",
    "### 2.2 Gestión de Valores Nulos\n",
    "Verificamos si existen valores nulos en el dataset y, en este ejemplo, optamos por eliminar las filas que los contengan.\n",
    "\n",
    "### 2.3 Ingeniería de Características: One-Hot Encoding\n",
    "Convertimos las variables categóricas (`City`, `State`, `Make` y `Model`) en variables dummy para poder trabajar con ellas en la red neuronal.\n",
    "\n",
    "### 2.4 Escalado de Variables Numéricas\n",
    "Las variables numéricas `Year` y `Mileage` se escalan utilizando `StandardScaler` para facilitar el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Price  Year  Mileage              City State   Make         Model\n",
      "0   8995  2014    35725           El Paso    TX  Acura    ILX6-Speed\n",
      "1  10888  2013    19606  Long Island City    NY  Acura    ILX5-Speed\n",
      "2   8995  2013    48851           El Paso    TX  Acura    ILX6-Speed\n",
      "3  10999  2014    39922           Windsor    CO  Acura    ILX5-Speed\n",
      "4  14799  2016    22142            Lindon    UT  Acura  ILXAutomatic\n",
      "\n",
      "Valores nulos por columna:\n",
      "Price      0\n",
      "Year       0\n",
      "Mileage    0\n",
      "City       0\n",
      "State      0\n",
      "Make       0\n",
      "Model      0\n",
      "dtype: int64\n",
      "\n",
      "Dimensiones del dataset tras el Label encoding: (852122, 7)\n",
      "\n",
      "Datos después del Label Encoding:\n",
      "   Price  Year  Mileage  City  State  Make  Model\n",
      "0   8995  2014    35725   646     49     1   1194\n",
      "1  10888  2013    19606  1260     39     1   1193\n",
      "2   8995  2013    48851   646     49     1   1194\n",
      "3  10999  2014    39922  2490      6     1   1193\n",
      "4  14799  2016    22142  1231     50     1   1196\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Eliminación de la columna 'Vin'\n",
    "df = df.drop('Vin', axis=1)\n",
    "print(df.head())\n",
    "\n",
    "# 2.2 Gestión de valores nulos\n",
    "print(\"\\nValores nulos por columna:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Eliminamos las filas con valores nulos\n",
    "df = df.dropna()\n",
    "\n",
    "# 2.3 Label Encoding para las variables categóricas\n",
    "categorical_cols = ['City', 'State', 'Make', 'Model']\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "print(\"\\nDimensiones del dataset tras el Label encoding:\", df.shape)\n",
    "\n",
    "# Revisamos algunas filas para confirmar el cambio\n",
    "print(\"\\nDatos después del Label Encoding:\")\n",
    "print(df.head())\n",
    "\n",
    "# # 2.4 Separación de la variable objetivo y las independientes\n",
    "# X = df_encoded.drop('Price', axis=1)\n",
    "# y = df_encoded['Price']\n",
    "\n",
    "# Separación de la variable objetivo y las independientes\n",
    "X = df.drop('Price', axis=1)\n",
    "y = df['Price']\n",
    "\n",
    "# Escalado de las variables numéricas 'Year' y 'Mileage'\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. División del Dataset en Conjuntos de Entrenamiento y Prueba\n",
    "\n",
    "Separamos los datos en un 80% para entrenamiento y un 20% para prueba. Esto nos permitirá evaluar el rendimiento del modelo en datos no vistos durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tamaño del conjunto de entrenamiento: (681697, 6)\n",
      "Tamaño del conjunto de prueba: (170425, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(\"\\nTamaño del conjunto de entrenamiento:\", X_train.shape)\n",
    "print(\"Tamaño del conjunto de prueba:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Construcción los modelos de Machine Learning (Regresión)\n",
    "\n",
    "Se crea un modelo secuencial con dos capas ocultas (64 neuronas cada una) y una capa de salida para regresión (una única neurona). Se compila el modelo utilizando el optimizador Adam, la función de pérdida MSE (error cuadrático medio) y se monitoriza el MAE (error absoluto medio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(\"Metricas: \")\n",
    "    print(f\"Mae: {mae} , R2_Score: {r2}\")\n",
    "    print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metricas: \n",
      "Mae: 7648.539482853907 , R2_Score: <function r2_score at 0x7fd0bd419ee0>\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "model1 = LinearRegression()\n",
    "models(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "#Predicciones\n",
    "y_pred = model.predict(X_test)\n",
    "#Metricas\n",
    "print(\"Metricas del modelo de regresion Random Forest\")\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"MAE: {mae}, RMSE: {rmse}, R²: {r2}\")\n",
    "print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "#Predicciones\n",
    "y_pred = model.predict(X_test)\n",
    "#Metricas\n",
    "print(\"Metricas del modelo de regresion Decision Tree\")\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"MAE: {mae}, RMSE: {rmse}, R²: {r2}\")\n",
    "print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metricas del modelo de regresion\n",
      "Mean Squared Error:  145763612.32787466\n",
      "R2 Score:  0.20718790178253965\n",
      "---------------------\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Crear y entrenar el modelo con kernel RBF\n",
    "svr = SVR(kernel='rbf', C=100, epsilon=0.1, gamma='scale')\n",
    "svr.fit(X_train, y_train)\n",
    "# Evaluación del modelo\n",
    "print(\"Metricas del modelo de regresion SVR\")\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"MAE: {mae}, RMSE: {rmse}, R²: {r2}\")\n",
    "print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "#Predicciones\n",
    "y_pred = model.predict(X_test)\n",
    "#Metricas\n",
    "print(\"Metricas del modelo de regresion XGBRegressor\")\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"MAE: {mae}, RMSE: {rmse}, R²: {r2}\")\n",
    "print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📊 Curva ROC\n",
    "La curva ROC (Receiver Operating Characteristic) es otra metrica que nos ayuda a determinar como de bien se comporta el modelo distinguiendo entre las clases positivas y negativas y a su vez nos permite seleccionar el mejor modelo para el problema que estamos tratando (Cuanto mas se aproxime a 1 en la grafica mejor desepeño tendra el modelo clasificando los registros)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "models = {\n",
    "    'LinearRegression': lr,\n",
    "    'RandomForestRegressor': rf,\n",
    "    'DecisionTreeRegressor': dt,\n",
    "    'SuperVectorRegressor': svm,\n",
    "    'XGBRegressor': xgb\n",
    "}\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "roc_auc_scores = {}\n",
    "\n",
    "# Initialize a dictionary to store AUC - ROC scores\n",
    "roc_auc_scores = {}\n",
    "\n",
    "# Plot the ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the probabilities\n",
    "    y_probs = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate the AUC - ROC score\n",
    "    roc_auc = roc_auc_score(y_test, y_probs)\n",
    "    roc_auc_scores[name] = roc_auc\n",
    "    \n",
    "    # Compute ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{name} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# Plot the diagonal 50% line\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Print the AUC - ROC scores for each model\n",
    "for name, score in roc_auc_scores.items():\n",
    "    print(f'{name}: AUC - ROC = {score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "En este notebook se ha demostrado cómo construir y entrenar un modelo de red neuronal para estimar el precio de vehículos usados. Se han realizado las siguientes tareas:\n",
    "- **Preprocesamiento de los datos**: limpieza, transformación de variables categóricas y escalado.\n",
    "- **División en conjuntos de entrenamiento y prueba**.\n",
    "- **Construcción de un modelo de red neuronal** utilizando Keras.\n",
    "- **Entrenamiento y visualización de la evolución de las métricas**.\n",
    "- **Evaluación del modelo** y comparación entre los valores reales y predichos.\n",
    "\n",
    "Este ejemplo puede ser la base para realizar mejoras adicionales en la arquitectura del modelo, el preprocesamiento de datos o incluso probar otras técnicas de ingeniería de características para mejorar la precisión del modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
